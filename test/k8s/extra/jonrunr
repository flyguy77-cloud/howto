1. Essentials: Wat JobRunr perfect doet voor jouw workflow

JobRunr kan:

✔ taken schedulen in de toekomst

(“run dit script morgen om 13:37”)

✔ taken sequentieel laten draaien

(niets start voordat de vorige klaar is)

✔ taken parallel laten draaien

(met jobBatch() of parallel streams)

✔ context meegeven

(execId, jobUid, script content, node metadata)

✔ distributed draaien (Redis / SQL / memory)

— belangrijk voor productie

✔ retries, dashboards, dead letter queues

— zonder dat jij dat zelf hoeft te implementeren

✔ perfect integreren met Spring Boot

(één annotatie en een @Service is genoeg)

En het mooiste:

Jouw K8s job-launcher wordt simpelweg een “unit of work” die JobRunr uitvoert.

⸻

2. Architectuur: hoe ziet dit eruit?

Workflow:
	•	bestaat uit nodes
	•	elke node verwijst naar script, GitLab reference, parameters
	•	edges bepalen volgorde/parallelisme

JobRunr:
	•	voert elke node uit als “BackgroundJob”
	•	bewaakt status per node
	•	jouw bestaande K8s-executor doet het échte werk

⸻

3. De mapping: workflow → JobRunr jobs

Dit is waar je blij van wordt, want je architectuur van nodes + edges + executor past perfect.

Een (sub)workflow = één JobRunr chain:

JobRunr workflow:
  └─ Node A
      └─ Node B
          └─ Node C

Parallel nodes:

Node A
 ├─ Node B (in parallel)
 ├─ Node C (in parallel)
 └─ Node D (in parallel)


⸻

4. Concreet voorbeeld – Sequential Workflow

Stel je hebt 3 nodes:
	•	Node1: download CSV
	•	Node2: run python analysis
	•	Node3: archive results

JobRunr code:

public class WorkflowScheduler {

    @Autowired
    private BackgroundJobClient jobClient;

    @Autowired
    private KubernetesJobExecutor executor;

    public UUID scheduleSequential(Workflow workflow) {

        // 1. Root job
        UUID rootJobId = jobClient.enqueue(() -> executor.runNode(workflow.getNode(1)));

        // 2. next jobs as continuation
        jobClient.enqueue(rootJobId,
                () -> executor.runNode(workflow.getNode(2)));

        jobClient.enqueue(rootJobId,
                () -> executor.runNode(workflow.getNode(3)));

        return rootJobId;
    }
}

Waar executor.runNode() is:

public void runNode(Node node) {
    // jouw bestaande K8s executor:
    UUID execId = jobExecutionService.execute(node.toDto());
    waitUntilJobComplete(execId);
}


⸻

5. Parallel nodes: zó simpel

JobRunr heeft een “job batch” API.

public UUID scheduleParallel(Collection<Node> nodes) {

    return jobClient.<Void>enqueue(() -> {
        JobRunrDashboard
            .getBackgroundJobClient()
            .createJobBatch(batch -> {
                for (Node node : nodes) {
                    batch.run(() -> executor.runNode(node));
                }
            });
    });
}

Parallel nodes draaien dus volledig onafhankelijk.

⸻

6. Hybrid workflow (parallel + sequential)

Stel:

Node A → [ Node B, Node C, Node D ] (parallel) → Node E

Dit is de real-world workflow automation flow.

public UUID scheduleHybrid(Workflow wf) {

    UUID jobId = jobClient.enqueue(() -> executor.runNode(wf.getNode("A")));

    // parallel nodes
    List<UUID> parallelJobs = new ArrayList<>();
    for (Node node : wf.getParallelNodes("A")) {
        parallelJobs.add(
            jobClient.enqueue(() -> executor.runNode(node))
        );
    }

    // continuation job depends on completion of all parallel nodes
    jobClient.enqueue(parallelJobs,
            () -> executor.runNode(wf.getNode("E")));

    return jobId;
}

JobRunr regelt:
	•	dependency management
	•	job tracking
	•	retries
	•	persistence
	•	monitoring dashboard

Jij hoeft niets ingewikkelds te bouwen.

⸻

7. Cron job scheduling

Wil jij:
	•	dagelijks workflows draaien
	•	elk uur caches verversen
	•	wekelijks analytics draaien

Super simpel:

RecurringJob.enqueue(
    "daily-workflow-" + wf.getId(),
    Cron.daily(),
    () -> scheduleSequential(wf)
);


⸻

8. Spring Boot configuratie (SUPER KORT)

application.properties:

org.jobrunr.database.type=postgresql
org.jobrunr.background-job-server.enabled=true
org.jobrunr.dashboard.enabled=true

Bean:

@Bean
public JobRunrConfigurer jobRunrConfigurer() {
    return JobRunr.configure()
        .useJobScheduler()
        .useBackgroundJobServer()
        .useDashboard()
        .initialize();
}

Klaar.

⸻

TL;DR (jouw preview)

Jij bouwt de workflow-engine

met nodes, edges, parameters, GitLab scripts, executor, scheduler, UI.

JobRunr voert de nodes uit

met retries, logging, scheduling en monitoring.

Jouw Kubernetes executor blijft je workhorse

→ JobRunr wordt alleen de orchestrator.

Sequentieel en parallel draaien is zó simpel
	•	enqueue()
	•	enqueue(rootJob, ...)
	•	createJobBatch()
	•	enqueue(jobsList, continuation)


+--------------------------------------------------------------------------------------+
|                                [Workflow Execution System]                           |
+--------------------------------------------------------------------------------------+

    +----------------------+        +------------------------------------+
    |  Controller Layer    |        |   WorkflowSchedulerService         |
    |   (start workflow)   | -----> | - scheduleWorkflow()               |
    +----------------------+        | - enqueue JobRunr root job         |
                                    +-------------------+----------------+
                                                        |
                                                        v
                                    +------------------------------------+
                                    |  BackgroundJobRequestHandler       |
                                    |  (JobRunr Orchestrator)           |
                                    |------------------------------------|
                                    | - startWorkflow(workflowId)        |
                                    | - scheduleNode(node)               |
                                    | - executeNode(workflow,node)       |
                                    | - determine next nodes             |
                                    +-------------------+----------------+
                                                        |
                                       triggers          | calls
                                                        v
                             +----------------------------------------------+
                             |                NodeExecutor                  |
                             |----------------------------------------------|
                             | - execute(node)                              |
                             | - koppeling met jouw Kubernetes JobExecutor |
                             +-------------------+--------------------------+
                                                        |
                                                        |
                                                        v
+------------------------+              +------------------------------+
| JobExecutionService    | <---------- | Kubernetes Cluster (Fabric8) |
| (bestaande K8s runner) |   status    | - Jobs                        |
| - start K8s job         |   logs      | - Pods                        |
| - monitoring            |             | - Log streams                 |
+------------------------+             +------------------------------+

                                        
                                      writes status/logs
                                        to database
                                              |
                                              v
                                    +--------------------------+
                                    |   Database Layer         |
                                    |--------------------------|
                                    | workflow_execution       |
                                    | workflow_node_execution  |
                                    | job_execution            |
                                    | job_execution_log        |
                                    +--------------------------+



	•	Controllers → ontvangen start-verzoeken
	•	WorkflowSchedulerService → maakt JobRunr root job aan
	•	BackgroundJobRequestHandler → orchestrator (de workflow-engine)
	•	NodeExecutor → bepaalt de uitvoering per node
	•	JobExecutionServiceImpl → jouw huidige Kubernetes job executor
	•	Kubernetes Cluster → voert echte workloads uit
	•	Database → status en logging

⸻

Wat JobRunr voor jou regelt

De Spring Boot starter van JobRunr regelt:
	•	de JobRunr BackgroundJobServer
	•	de JobRunr Dashboard
	•	threadpools
	•	retries
	•	persistente job storage
	•	idempotentie
	•	distributed execution
	•	automatische retry policies
	•	dead-letter queues

Dus je hoeft geen eigen threadpools of schedulers meer te bouwen.

Dat betekent dat JIJ in jouw applicatie maar twee dingen nodig hebt:

⸻

1. WorkflowSchedulerService (de entrypoint voor workflows)

Deze doet:
	•	workflow uit database ophalen
	•	workflow execution ID genereren
	•	de root van de workflow enqueue-en via JobRunr

Voorbeeld:

@Service
@RequiredArgsConstructor
public class WorkflowSchedulerService {

    private final BackgroundJobRequestHandler handler;

    public UUID scheduleWorkflow(UUID workflowId) {

        UUID execId = UUID.randomUUID();

        BackgroundJob.enqueue(() ->
            handler.startWorkflow(workflowId, execId)
        );

        return execId;
    }
}

Dit is letterlijk je “start workflow” façade.

⸻

2. BackgroundJobRequestHandler (de orkestrator / workflow engine)

Deze is de core workflow-engine, maar nog steeds best compact.

Hij doet:
	•	startWorkflow() → zoekt startnodes → plant die in
	•	executeNode() → voert node uit → plant volgende nodes in
	•	beheert de branching, ALL/ANY gateways, parallelisme
	•	koppelt met jouw bestaande Kubernetes executor

Voorbeeld:

@Service
@RequiredArgsConstructor
public class BackgroundJobRequestHandler {

    private final WorkflowRepository wfRepo;
    private final NodeExecutor nodeExecutor;

    public void startWorkflow(UUID workflowId, UUID execId) {
        var wf = wfRepo.findById(workflowId).orElseThrow();
        var startNodes = wf.getStartNodes();

        for (var node : startNodes) {
            scheduleNode(wf.getId(), node.getId(), execId);
        }
    }

    private void scheduleNode(UUID workflowId, UUID nodeId, UUID execId) {
        BackgroundJob.enqueue(() ->
            executeNode(workflowId, nodeId, execId)
        );
    }

    public void executeNode(UUID workflowId, UUID nodeId, UUID execId) {
        var wf = wfRepo.findById(workflowId).orElseThrow();
        var node = wf.findNode(nodeId);

        var result = nodeExecutor.execute(node, execId);

        for (var next : wf.getNextNodes(node)) {
            if (wf.shouldTrigger(next, execId))
                scheduleNode(workflowId, next.getId(), execId);
        }
    }
}

Meer is het niet.
JobRunr doet al het “moeilijke werk”.

⸻

3. NodeExecutor (optioneel — maar praktisch gezien wél nodig)

Omdat jij K8s runt:

@Service
@RequiredArgsConstructor
public class NodeExecutor {

    private final JobExecutionServiceImpl k8sExecutor;

    public NodeResult execute(NodeEntity node, UUID execId) {
        return switch (node.getType()) {
            case RUN_SCRIPT -> runScript(node, execId);
            case LOAD_SCRIPT -> load(node);
            default -> new NodeResult("OK", true);
        };
    }

    private NodeResult runScript(NodeEntity node, UUID execId) {
        UUID jobId = k8sExecutor.execute(node.toDto());
        return new NodeResult(jobId.toString(), true);
    }
}

Niet verplicht, maar maakt je code extreem clean.

⸻

Dus… heb je écht alleen 2 Spring services nodig?

✔ Ja voor JobRunr integratie

✔ Ja voor workflow scheduling

✔ Ja voor node orchestration

Maar je hebt daarnaast nog steeds je bestaande Kubernetes executor nodig

(en je status/log watchers blijven actief, maar die staan al volledig los van JobRunr).

⸻

Voor JobRunr heb je exact nodig:

1. WorkflowSchedulerService

→ ontvangt “run workflow”
→ start JobRunr root job

2. BackgroundJobRequestHandler

→ voert nodes uit
→ plant vervolg-nodes in
→ doet parallel branching
→ koppelt met jouw K8s executor
